---
title: æ¨¡å‹è¯„ä¼°å’Œé€‰æ‹©
published: 2025-7-29 23:59:59
slug: model-evaluation-and-selection
tags: ['æ·±åº¦å­¦ä¹ ', 'æœºå™¨å­¦ä¹ ', 'æ¨¡å‹è¯„ä¼°']
category: 'æœºå™¨å­¦ä¹ '
draft: false
image: ./bg.jpg
---

## æ¨¡å‹è¯„ä¼°å’Œé€‰æ‹©

## å‰è¨€

åœ¨æœºå™¨å­¦ä¹ çš„å­¦ä¹ è·¯å¾„ä¸­ï¼ŒæŒæ¡äº†å„ç§ç®—æ³•åï¼Œä¸‹ä¸€ä¸ªå…³é”®é—®é¢˜å°±æ˜¯ï¼š**å¦‚ä½•çŸ¥é“æˆ‘çš„æ¨¡å‹å¥½ä¸å¥½ï¼Ÿå¦‚ä½•åœ¨å¤šä¸ªæ¨¡å‹ä¸­é€‰æ‹©æœ€ä¼˜çš„ï¼Ÿ** è¿™å°±æ˜¯æ¨¡å‹è¯„ä¼°å’Œé€‰æ‹©çš„æ ¸å¿ƒé—®é¢˜ã€‚

ä»Šå¤©æ·±å…¥å­¦ä¹ äº†æ¨¡å‹è¯„ä¼°çš„å„ç§æŒ‡æ ‡ã€äº¤å‰éªŒè¯æŠ€æœ¯ï¼Œä»¥åŠåå·®-æ–¹å·®æƒè¡¡ç†è®ºã€‚æˆ‘å‘ç°ï¼Œä»…ä»…çŸ¥é“å¦‚ä½•è®­ç»ƒæ¨¡å‹æ˜¯è¿œè¿œä¸å¤Ÿçš„ï¼Œæ›´é‡è¦çš„æ˜¯è¦èƒ½å¤Ÿç§‘å­¦åœ°è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œç†è§£æ¨¡å‹çš„ä¼˜ç¼ºç‚¹ï¼Œå¹¶æ®æ­¤åšå‡ºåˆç†çš„æ¨¡å‹é€‰æ‹©ã€‚

è¿™ä»½ç¬”è®°è®°å½•äº†æˆ‘å¯¹æ¨¡å‹è¯„ä¼°ä½“ç³»çš„ç†è§£ï¼Œä»åŸºç¡€çš„æ··æ·†çŸ©é˜µåˆ°é«˜çº§çš„åå·®-æ–¹å·®åˆ†è§£ï¼Œå¸Œæœ›èƒ½ä¸ºåç»­çš„æœºå™¨å­¦ä¹ å®è·µæä¾›åšå®çš„è¯„ä¼°åŸºç¡€ã€‚

## ç¬¬ä¸€éƒ¨åˆ†ï¼šåˆ†ç±»é—®é¢˜è¯„ä¼°æŒ‡æ ‡

### 1.1 æ··æ·†çŸ©é˜µï¼šç†è§£åˆ†ç±»é”™è¯¯çš„"åœ°å›¾"

#### 1.1.1 æ··æ·†çŸ©é˜µçš„æ•°å­¦å®šä¹‰

æ··æ·†çŸ©é˜µæ˜¯è¯„ä¼°åˆ†ç±»æ¨¡å‹æ€§èƒ½çš„åŸºç¡€å·¥å…·ã€‚å¯¹äºkç±»åˆ†ç±»é—®é¢˜ï¼Œæ··æ·†çŸ©é˜µæ˜¯ä¸€ä¸ªkÃ—kçš„æ–¹é˜µï¼š

$$C_{ij} = \text{é¢„æµ‹ä¸ºç±»åˆ«jä½†å®é™…ä¸ºç±»åˆ«içš„æ ·æœ¬æ•°é‡}$$

**äºŒåˆ†ç±»æ··æ·†çŸ©é˜µçš„æ ‡å‡†å½¢å¼ï¼š**

```text
                é¢„æµ‹ç»“æœ
              æ­£ç±»    è´Ÿç±»
çœŸå®  æ­£ç±»    TP     FN
æ ‡ç­¾  è´Ÿç±»    FP     TN
```

å…¶ä¸­ï¼š

- **TP (True Positive)**ï¼šçœŸæ­£ä¾‹ - é¢„æµ‹ä¸ºæ­£ï¼Œå®é™…ä¹Ÿä¸ºæ­£
- **TN (True Negative)**ï¼šçœŸè´Ÿä¾‹ - é¢„æµ‹ä¸ºè´Ÿï¼Œå®é™…ä¹Ÿä¸ºè´Ÿ  
- **FP (False Positive)**ï¼šå‡æ­£ä¾‹ - é¢„æµ‹ä¸ºæ­£ï¼Œå®é™…ä¸ºè´Ÿï¼ˆç¬¬ä¸€ç±»é”™è¯¯ï¼‰
- **FN (False Negative)**ï¼šå‡è´Ÿä¾‹ - é¢„æµ‹ä¸ºè´Ÿï¼Œå®é™…ä¸ºæ­£ï¼ˆç¬¬äºŒç±»é”™è¯¯ï¼‰

#### 1.1.2 ä»æ··æ·†çŸ©é˜µå¯¼å‡ºçš„åŸºæœ¬æŒ‡æ ‡

**1. å‡†ç¡®ç‡ (Accuracy)**
$$\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}$$

- **å«ä¹‰**ï¼šæ‰€æœ‰é¢„æµ‹ä¸­æ­£ç¡®é¢„æµ‹çš„æ¯”ä¾‹
- **é€‚ç”¨åœºæ™¯**ï¼šç±»åˆ«å¹³è¡¡çš„æ•°æ®é›†
- **å±€é™æ€§**ï¼šåœ¨ä¸å¹³è¡¡æ•°æ®é›†ä¸Šå®¹æ˜“äº§ç”Ÿè¯¯å¯¼

**2. ç²¾ç¡®ç‡ (Precision)**
$$\text{Precision} = \frac{TP}{TP + FP}$$

- **å«ä¹‰**ï¼šåœ¨æ‰€æœ‰é¢„æµ‹ä¸ºæ­£çš„æ ·æœ¬ä¸­ï¼ŒçœŸæ­£ä¸ºæ­£çš„æ¯”ä¾‹
- **ç›´è§‚ç†è§£**ï¼šæ¨¡å‹è¯´"æ˜¯"çš„æ—¶å€™ï¼Œæœ‰å¤šå°‘æ¬¡æ˜¯å¯¹çš„
- **ä¸šåŠ¡æ„ä¹‰**ï¼šå½“è¯¯æŠ¥ä»£ä»·å¾ˆé«˜æ—¶ï¼ˆå¦‚åƒåœ¾é‚®ä»¶æ£€æµ‹ï¼‰ï¼Œéœ€è¦é«˜ç²¾ç¡®ç‡

**3. å¬å›ç‡ (Recall/Sensitivity)**
$$\text{Recall} = \frac{TP}{TP + FN}$$

- **å«ä¹‰**ï¼šåœ¨æ‰€æœ‰çœŸæ­£ä¸ºæ­£çš„æ ·æœ¬ä¸­ï¼Œè¢«æ­£ç¡®é¢„æµ‹çš„æ¯”ä¾‹
- **ç›´è§‚ç†è§£**ï¼šæ‰€æœ‰çœŸæ­£çš„"é˜³æ€§"ä¸­ï¼Œæ¨¡å‹æ‰¾åˆ°äº†å¤šå°‘
- **ä¸šåŠ¡æ„ä¹‰**ï¼šå½“æ¼æŠ¥ä»£ä»·å¾ˆé«˜æ—¶ï¼ˆå¦‚ç–¾ç—…è¯Šæ–­ï¼‰ï¼Œéœ€è¦é«˜å¬å›ç‡

**4. ç‰¹å¼‚æ€§ (Specificity)**
$$\text{Specificity} = \frac{TN}{TN + FP}$$

- **å«ä¹‰**ï¼šåœ¨æ‰€æœ‰çœŸæ­£ä¸ºè´Ÿçš„æ ·æœ¬ä¸­ï¼Œè¢«æ­£ç¡®é¢„æµ‹çš„æ¯”ä¾‹
- **ç›´è§‚ç†è§£**ï¼šæ¨¡å‹æ­£ç¡®è¯†åˆ«"é˜´æ€§"çš„èƒ½åŠ›

**5. F1åˆ†æ•°**
$$F1 = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}} = \frac{2TP}{2TP + FP + FN}$$

- **å«ä¹‰**ï¼šç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡æ•°
- **ä¼˜åŠ¿**ï¼šå¹³è¡¡è€ƒè™‘ç²¾ç¡®ç‡å’Œå¬å›ç‡ï¼Œå¯¹ä¸å¹³è¡¡æ•°æ®é›†è¾ƒä¸ºç¨³å¥

#### 1.1.3 å®ç°å®Œæ•´çš„è¯„ä¼°å™¨

```python
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import *
from sklearn.model_selection import learning_curve, validation_curve

class ModelEvaluator:
    """å®Œæ•´çš„æ¨¡å‹è¯„ä¼°å™¨"""
    
    def __init__(self):
        pass
    
    def plot_confusion_matrix(self, y_true, y_pred, classes=None, normalize=False):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µå¹¶æä¾›è¯¦ç»†åˆ†æ"""
        
        cm = confusion_matrix(y_true, y_pred)
        
        if normalize:
            cm_display = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
            title = 'æ ‡å‡†åŒ–æ··æ·†çŸ©é˜µ'
            fmt = '.2f'
        else:
            cm_display = cm
            title = 'æ··æ·†çŸ©é˜µ'
            fmt = 'd'
        
        # åˆ›å»ºå­å›¾ï¼šåŸå§‹çŸ©é˜µå’Œæ ‡å‡†åŒ–çŸ©é˜µ
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        
        # åŸå§‹æ··æ·†çŸ©é˜µ
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=classes, yticklabels=classes, ax=axes[0])
        axes[0].set_title('åŸå§‹æ··æ·†çŸ©é˜µ')
        axes[0].set_ylabel('çœŸå®æ ‡ç­¾')
        axes[0].set_xlabel('é¢„æµ‹æ ‡ç­¾')
        
        # æ ‡å‡†åŒ–æ··æ·†çŸ©é˜µ
        cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues',
                   xticklabels=classes, yticklabels=classes, ax=axes[1])
        axes[1].set_title('æ ‡å‡†åŒ–æ··æ·†çŸ©é˜µ (æŒ‰è¡Œå½’ä¸€åŒ–)')
        axes[1].set_ylabel('çœŸå®æ ‡ç­¾')
        axes[1].set_xlabel('é¢„æµ‹æ ‡ç­¾')
        
        plt.tight_layout()
        plt.show()
        
        # è¯¦ç»†åˆ†æ
        self._analyze_confusion_matrix(cm, classes)
        
        return cm
    
    def _analyze_confusion_matrix(self, cm, classes):
        """åˆ†ææ··æ·†çŸ©é˜µçš„è¯¦ç»†ä¿¡æ¯"""
        
        print("=== æ··æ·†çŸ©é˜µè¯¦ç»†åˆ†æ ===")
        
        if len(cm) == 2:  # äºŒåˆ†ç±»
            tn, fp, fn, tp = cm.ravel()
            print(f"çœŸè´Ÿä¾‹ (TN): {tn}")
            print(f"å‡æ­£ä¾‹ (FP): {fp} - ç¬¬ä¸€ç±»é”™è¯¯")
            print(f"å‡è´Ÿä¾‹ (FN): {fn} - ç¬¬äºŒç±»é”™è¯¯")  
            print(f"çœŸæ­£ä¾‹ (TP): {tp}")
            print(f"æ€»é¢„æµ‹é”™è¯¯: {fp + fn} / {cm.sum()}")
            
            # é”™è¯¯ç±»å‹åˆ†æ
            if fp > fn:
                print("ä¸»è¦é”™è¯¯ç±»å‹: å‡æ­£ä¾‹ (è¿‡åº¦é¢„æµ‹)")
            elif fn > fp:
                print("ä¸»è¦é”™è¯¯ç±»å‹: å‡è´Ÿä¾‹ (é¢„æµ‹ä¸è¶³)")
            else:
                print("å‡æ­£ä¾‹å’Œå‡è´Ÿä¾‹ç›¸å½“")
        else:  # å¤šåˆ†ç±»
            print("å„ç±»åˆ«é¢„æµ‹æƒ…å†µ:")
            for i, class_name in enumerate(classes or range(len(cm))):
                correct = cm[i, i]
                total = cm[i, :].sum()
                accuracy = correct / total if total > 0 else 0
                print(f"  {class_name}: {correct}/{total} = {accuracy:.3f}")
    
    def classification_metrics(self, y_true, y_pred, y_prob=None, target_names=None):
        """è®¡ç®—å…¨é¢çš„åˆ†ç±»æŒ‡æ ‡"""
        
        print("=== åŸºæœ¬åˆ†ç±»æŒ‡æ ‡ ===")
        
        # åŸºæœ¬æŒ‡æ ‡
        accuracy = accuracy_score(y_true, y_pred)
        precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)
        recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)
        
        print(f"å‡†ç¡®ç‡ (Accuracy): {accuracy:.4f}")
        print(f"ç²¾ç¡®ç‡ (Precision): {precision:.4f}")
        print(f"å¬å›ç‡ (Recall): {recall:.4f}")
        print(f"F1åˆ†æ•°: {f1:.4f}")
        
        # è¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Š
        print("\n=== è¯¦ç»†åˆ†ç±»æŠ¥å‘Š ===")
        print(classification_report(y_true, y_pred, target_names=target_names))
        
        # AUCç›¸å…³æŒ‡æ ‡
        if y_prob is not None:
            n_classes = len(np.unique(y_true))
            
            if n_classes == 2:  # äºŒåˆ†ç±»
                # ç¡®ä¿y_probæ˜¯æ¦‚ç‡å½¢å¼
                if y_prob.ndim == 2:
                    y_prob_binary = y_prob[:, 1]
                else:
                    y_prob_binary = y_prob
                
                auc = roc_auc_score(y_true, y_prob_binary)
                ap = average_precision_score(y_true, y_prob_binary)
                
                print(f"\n=== æ¦‚ç‡ç›¸å…³æŒ‡æ ‡ ===")
                print(f"AUC-ROC: {auc:.4f}")
                print(f"å¹³å‡ç²¾ç¡®ç‡ (AP): {ap:.4f}")
                
                # ç»˜åˆ¶ROCå’ŒPRæ›²çº¿
                self.plot_roc_curve(y_true, y_prob_binary)
                self.plot_precision_recall_curve(y_true, y_prob_binary)
                
            else:  # å¤šåˆ†ç±»
                try:
                    auc = roc_auc_score(y_true, y_prob, multi_class='ovr', average='weighted')
                    print(f"\n=== å¤šåˆ†ç±»æ¦‚ç‡æŒ‡æ ‡ ===")
                    print(f"å¤šåˆ†ç±»AUC-ROC: {auc:.4f}")
                except ValueError as e:
                    print(f"æ— æ³•è®¡ç®—å¤šåˆ†ç±»AUC: {e}")
        
        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1
        }
    
    def plot_roc_curve(self, y_true, y_prob):
        """ç»˜åˆ¶ROCæ›²çº¿åŠè¯¦ç»†åˆ†æ"""
        
        fpr, tpr, thresholds = roc_curve(y_true, y_prob)
        auc = roc_auc_score(y_true, y_prob)
        
        plt.figure(figsize=(12, 5))
        
        # ROCæ›²çº¿
        plt.subplot(1, 2, 1)
        plt.plot(fpr, tpr, linewidth=2, label=f'ROCæ›²çº¿ (AUC = {auc:.3f})')
        plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='éšæœºåˆ†ç±»å™¨ (AUC = 0.5)')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('å‡æ­£ç‡ (FPR) = FP/(FP+TN)')
        plt.ylabel('çœŸæ­£ç‡ (TPR) = TP/(TP+FN)')
        plt.title('ROCæ›²çº¿')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # é˜ˆå€¼åˆ†æ
        plt.subplot(1, 2, 2)
        plt.plot(thresholds, fpr, label='å‡æ­£ç‡ (FPR)', linewidth=2)
        plt.plot(thresholds, tpr, label='çœŸæ­£ç‡ (TPR)', linewidth=2)
        plt.xlabel('åˆ†ç±»é˜ˆå€¼')
        plt.ylabel('ç‡')
        plt.title('é˜ˆå€¼ vs FPR/TPR')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        # æœ€ä¼˜é˜ˆå€¼åˆ†æ
        optimal_idx = np.argmax(tpr - fpr)  # YoudenæŒ‡æ•°
        optimal_threshold = thresholds[optimal_idx]
        print(f"æœ€ä¼˜é˜ˆå€¼ (YoudenæŒ‡æ•°): {optimal_threshold:.3f}")
        print(f"å¯¹åº”TPR: {tpr[optimal_idx]:.3f}, FPR: {fpr[optimal_idx]:.3f}")
    
    def plot_precision_recall_curve(self, y_true, y_prob):
        """ç»˜åˆ¶ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿"""
        
        precision, recall, thresholds = precision_recall_curve(y_true, y_prob)
        ap = average_precision_score(y_true, y_prob)
        
        # è®¡ç®—åŸºçº¿ï¼ˆéšæœºé¢„æµ‹çš„APï¼‰
        baseline_ap = np.sum(y_true) / len(y_true)
        
        plt.figure(figsize=(12, 5))
        
        # PRæ›²çº¿
        plt.subplot(1, 2, 1)
        plt.plot(recall, precision, linewidth=2, label=f'PRæ›²çº¿ (AP = {ap:.3f})')
        plt.axhline(y=baseline_ap, color='k', linestyle='--', 
                   linewidth=1, label=f'éšæœºåˆ†ç±»å™¨ (AP = {baseline_ap:.3f})')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('å¬å›ç‡ (Recall)')
        plt.ylabel('ç²¾ç¡®ç‡ (Precision)')
        plt.title('ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # F1åˆ†æ•° vs é˜ˆå€¼
        plt.subplot(1, 2, 2)
        f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])
        plt.plot(thresholds, f1_scores, linewidth=2, label='F1åˆ†æ•°')
        optimal_f1_idx = np.argmax(f1_scores)
        optimal_f1_threshold = thresholds[optimal_f1_idx]
        plt.axvline(x=optimal_f1_threshold, color='r', linestyle='--', 
                   label=f'æœ€ä¼˜F1é˜ˆå€¼ = {optimal_f1_threshold:.3f}')
        plt.xlabel('åˆ†ç±»é˜ˆå€¼')
        plt.ylabel('F1åˆ†æ•°')
        plt.title('F1åˆ†æ•° vs é˜ˆå€¼')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        print(f"æœ€ä¼˜F1é˜ˆå€¼: {optimal_f1_threshold:.3f}")
        print(f"æœ€å¤§F1åˆ†æ•°: {f1_scores[optimal_f1_idx]:.3f}")
```

### 1.2 ROCæ›²çº¿å’ŒAUCï¼šç†è§£åˆ†ç±»å™¨çš„åˆ¤åˆ«èƒ½åŠ›

#### 1.2.1 ROCæ›²çº¿çš„æ•°å­¦åŸºç¡€

ROC (Receiver Operating Characteristic) æ›²çº¿æ˜¯åœ¨ä¸åŒåˆ†ç±»é˜ˆå€¼ä¸‹ï¼ŒçœŸæ­£ç‡(TPR)å¯¹å‡æ­£ç‡(FPR)çš„å‡½æ•°å›¾åƒã€‚

**æ•°å­¦å®šä¹‰ï¼š**

- **TPR (True Positive Rate)** = $\frac{TP}{TP + FN}$ = Recall = Sensitivity
- **FPR (False Positive Rate)** = $\frac{FP}{FP + TN}$ = 1 - Specificity

**AUC (Area Under Curve) çš„å«ä¹‰ï¼š**
AUCç­‰äºä»æ­£ç±»å’Œè´Ÿç±»ä¸­å„éšæœºé€‰æ‹©ä¸€ä¸ªæ ·æœ¬ï¼Œåˆ†ç±»å™¨ç»™æ­£ç±»æ ·æœ¬çš„è¯„åˆ†é«˜äºè´Ÿç±»æ ·æœ¬è¯„åˆ†çš„æ¦‚ç‡ã€‚

$$\text{AUC} = P(S_+ > S_- | \text{éšæœºé€‰æ‹©æ­£è´Ÿæ ·æœ¬})$$

**AUCçš„æ€§è´¨ï¼š**

- AUC âˆˆ [0, 1]
- AUC = 0.5ï¼šéšæœºåˆ†ç±»å™¨
- AUC = 1ï¼šå®Œç¾åˆ†ç±»å™¨
- AUC > 0.5ï¼šæ¯”éšæœºåˆ†ç±»å¥½
- AUC < 0.5ï¼šæ¯”éšæœºåˆ†ç±»å·®ï¼ˆå¯ä»¥åè½¬é¢„æµ‹ï¼‰

#### 1.2.2 PRæ›²çº¿ vs ROCæ›²çº¿

**é€‰æ‹©åŸåˆ™ï¼š**

- **å¹³è¡¡æ•°æ®é›†**ï¼šROCæ›²çº¿å’ŒPRæ›²çº¿éƒ½æœ‰æ•ˆ
- **ä¸å¹³è¡¡æ•°æ®é›†**ï¼šPRæ›²çº¿æ›´èƒ½åæ˜ çœŸå®æ€§èƒ½

**æ•°å­¦åŸå› ï¼š**
åœ¨æä¸å¹³è¡¡æ•°æ®é›†ä¸­ï¼ˆå¦‚æ­£ç±»å 1%ï¼‰ï¼Œå³ä½¿FPRå¾ˆå°ï¼ŒFPçš„ç»å¯¹æ•°é‡å¯èƒ½å¾ˆå¤§ï¼Œå¯¼è‡´ç²¾ç¡®ç‡å¾ˆä½ï¼Œä½†ROCæ›²çº¿çœ‹èµ·æ¥ä»ç„¶ä¸é”™ã€‚

**å®ä¾‹æ¯”è¾ƒï¼š**
å‡è®¾æ•°æ®é›†ï¼š990ä¸ªè´Ÿä¾‹ï¼Œ10ä¸ªæ­£ä¾‹

- æ¨¡å‹é¢„æµ‹ï¼š8ä¸ªçœŸæ­£ä¾‹ï¼Œ2ä¸ªå‡è´Ÿä¾‹ï¼Œ100ä¸ªå‡æ­£ä¾‹ï¼Œ890ä¸ªçœŸè´Ÿä¾‹
- ROCè§’åº¦ï¼šTPR = 8/10 = 0.8ï¼ŒFPR = 100/990 = 0.101 (çœ‹èµ·æ¥ä¸é”™)
- PRè§’åº¦ï¼šPrecision = 8/108 = 0.074 (å¾ˆå·®!)

### 1.3 å¤šåˆ†ç±»è¯„ä¼°çš„ç‰¹æ®Šè€ƒè™‘

#### 1.3.1 å¹³å‡ç­–ç•¥

å¯¹äºå¤šåˆ†ç±»é—®é¢˜ï¼Œéœ€è¦é€‰æ‹©åˆé€‚çš„å¹³å‡ç­–ç•¥ï¼š

**1. Macroå¹³å‡**
$$\text{Macro-F1} = \frac{1}{k}\sum_{i=1}^{k} F1_i$$

- æ¯ä¸ªç±»åˆ«æƒé‡ç›¸ç­‰
- é€‚ç”¨äºå…³å¿ƒæ¯ä¸ªç±»åˆ«æ€§èƒ½çš„åœºæ™¯

**2. Weightedå¹³å‡**
$$\text{Weighted-F1} = \sum_{i=1}^{k} w_i \times F1_i, \quad w_i = \frac{n_i}{n}$$

- æŒ‰ç±»åˆ«æ ·æœ¬æ•°é‡åŠ æƒ
- é€‚ç”¨äºç±»åˆ«ä¸å¹³è¡¡ä½†æ›´å…³å¿ƒå¤§ç±»åˆ«çš„åœºæ™¯

**3. Microå¹³å‡**
$$\text{Micro-F1} = \frac{2 \times \sum_{i=1}^{k} TP_i}{2 \times \sum_{i=1}^{k} TP_i + \sum_{i=1}^{k} FP_i + \sum_{i=1}^{k} FN_i}$$

- èšåˆæ‰€æœ‰ç±»åˆ«çš„TPã€FPã€FNåè®¡ç®—
- ç­‰ä»·äºå‡†ç¡®ç‡

## ç¬¬äºŒéƒ¨åˆ†ï¼šå›å½’é—®é¢˜è¯„ä¼°æŒ‡æ ‡

### 2.1 å¸¸ç”¨å›å½’æŒ‡æ ‡

#### 2.1.1 åŸºæœ¬è¯¯å·®æŒ‡æ ‡

**1. å¹³å‡ç»å¯¹è¯¯å·® (MAE)**
$$\text{MAE} = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|$$

- **ä¼˜ç‚¹**ï¼šç›´è§‚æ˜“æ‡‚ï¼Œä¸ç›®æ ‡å˜é‡åŒå•ä½ï¼Œå¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿ
- **ç¼ºç‚¹**ï¼šä¸å¯å¾®åˆ†ï¼Œä¼˜åŒ–å›°éš¾

**2. å‡æ–¹è¯¯å·® (MSE)**
$$\text{MSE} = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2$$

- **ä¼˜ç‚¹**ï¼šå¯å¾®åˆ†ï¼Œä¾¿äºä¼˜åŒ–ï¼Œæƒ©ç½šå¤§è¯¯å·®
- **ç¼ºç‚¹**ï¼šå•ä½æ˜¯ç›®æ ‡å˜é‡çš„å¹³æ–¹ï¼Œå¯¹å¼‚å¸¸å€¼æ•æ„Ÿ

**3. å‡æ–¹æ ¹è¯¯å·® (RMSE)**
$$\text{RMSE} = \sqrt{\text{MSE}} = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}$$

- **ä¼˜ç‚¹**ï¼šä¸ç›®æ ‡å˜é‡åŒå•ä½ï¼Œå…¼å…·MSEçš„å¯å¾®æ€§
- **ç¼ºç‚¹**ï¼šä»å¯¹å¼‚å¸¸å€¼æ•æ„Ÿ

**4. å†³å®šç³»æ•° (RÂ²)**
$$R^2 = 1 - \frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2} = 1 - \frac{\text{SS}_{\text{res}}}{\text{SS}_{\text{tot}}}$$

- **å«ä¹‰**ï¼šæ¨¡å‹è§£é‡Šçš„æ–¹å·®å æ€»æ–¹å·®çš„æ¯”ä¾‹
- **èŒƒå›´**ï¼š(-âˆ, 1]ï¼Œ1è¡¨ç¤ºå®Œç¾æ‹Ÿåˆ
- **ä¼˜ç‚¹**ï¼šæ— é‡çº²ï¼Œä¾¿äºä¸åŒé—®é¢˜é—´æ¯”è¾ƒ

#### 2.1.2 é«˜çº§å›å½’æŒ‡æ ‡

**5. å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·® (MAPE)**
$$\text{MAPE} = \frac{100\%}{n}\sum_{i=1}^{n}\left|\frac{y_i - \hat{y}_i}{y_i}\right|$$

- **é€‚ç”¨**ï¼šç›¸å¯¹è¯¯å·®æ›´é‡è¦çš„åœºæ™¯
- **å±€é™**ï¼šå½“çœŸå®å€¼æ¥è¿‘0æ—¶ä¸ç¨³å®š

**6. å¯¹ç§°å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·® (sMAPE)**
$$\text{sMAPE} = \frac{100\%}{n}\sum_{i=1}^{n}\frac{|y_i - \hat{y}_i|}{(|y_i| + |\hat{y}_i|)/2}$$

- **æ”¹è¿›**ï¼šè§£å†³MAPEåœ¨çœŸå®å€¼ä¸º0æ—¶çš„é—®é¢˜

#### 2.1.3 å›å½’è¯„ä¼°çš„å®Œæ•´å®ç°

```python
def regression_metrics(y_true, y_pred, multioutput='uniform_average'):
    """å›å½’é—®é¢˜çš„å®Œæ•´è¯„ä¼°"""
    
    # åŸºæœ¬æŒ‡æ ‡
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)
    
    # é¢å¤–æŒ‡æ ‡
    evs = explained_variance_score(y_true, y_pred)  # è§£é‡Šæ–¹å·®å¾—åˆ†
    max_error = max_error(y_true, y_pred)  # æœ€å¤§è¯¯å·®
    
    print("=== å›å½’è¯„ä¼°æŒ‡æ ‡ ===")
    print(f"å¹³å‡ç»å¯¹è¯¯å·® (MAE): {mae:.4f}")
    print(f"å‡æ–¹è¯¯å·® (MSE): {mse:.4f}")
    print(f"å‡æ–¹æ ¹è¯¯å·® (RMSE): {rmse:.4f}")
    print(f"å†³å®šç³»æ•° (RÂ²): {r2:.4f}")
    print(f"è§£é‡Šæ–¹å·®å¾—åˆ†: {evs:.4f}")
    print(f"æœ€å¤§è¯¯å·®: {max_error:.4f}")
    
    # è®¡ç®—ç™¾åˆ†æ¯”è¯¯å·®ï¼ˆé¿å…é™¤é›¶ï¼‰
    mask = y_true != 0
    if np.any(mask):
        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100
        print(f"å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·® (MAPE): {mape:.2f}%")
    
    # æ®‹å·®åˆ†æ
    residuals = y_true - y_pred
    
    plt.figure(figsize=(15, 10))
    
    # 1. é¢„æµ‹å€¼ vs çœŸå®å€¼
    plt.subplot(2, 3, 1)
    plt.scatter(y_true, y_pred, alpha=0.6, edgecolors='k', linewidth=0.5)
    min_val, max_val = min(y_true.min(), y_pred.min()), max(y_true.max(), y_pred.max())
    plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='å®Œç¾é¢„æµ‹çº¿')
    plt.xlabel('çœŸå®å€¼')
    plt.ylabel('é¢„æµ‹å€¼')
    plt.title(f'é¢„æµ‹å€¼ vs çœŸå®å€¼\n(RÂ² = {r2:.3f})')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # 2. æ®‹å·®å›¾
    plt.subplot(2, 3, 2)
    plt.scatter(y_pred, residuals, alpha=0.6, edgecolors='k', linewidth=0.5)
    plt.axhline(y=0, color='r', linestyle='--', linewidth=2)
    plt.xlabel('é¢„æµ‹å€¼')
    plt.ylabel('æ®‹å·® (çœŸå®å€¼ - é¢„æµ‹å€¼)')
    plt.title('æ®‹å·®å›¾')
    plt.grid(True, alpha=0.3)
    
    # æ£€æŸ¥åŒæ–¹å·®æ€§
    # è®¡ç®—æ®‹å·®çš„ç»å¯¹å€¼ä¸é¢„æµ‹å€¼çš„ç›¸å…³æ€§
    abs_residuals = np.abs(residuals)
    heteroscedasticity = np.corrcoef(y_pred, abs_residuals)[0, 1]
    plt.text(0.05, 0.95, f'å¼‚æ–¹å·®æ€§æ£€éªŒ\nç›¸å…³ç³»æ•°: {heteroscedasticity:.3f}', 
             transform=plt.gca().transAxes, bbox=dict(boxstyle="round", facecolor='wheat'))
    
    # 3. æ®‹å·®åˆ†å¸ƒ
    plt.subplot(2, 3, 3)
    plt.hist(residuals, bins=30, alpha=0.7, edgecolor='black')
    plt.xlabel('æ®‹å·®')
    plt.ylabel('é¢‘æ•°')
    plt.title('æ®‹å·®åˆ†å¸ƒ')
    plt.grid(True, alpha=0.3)
    
    # æ­£æ€æ€§æ£€éªŒ
    from scipy import stats
    shapiro_stat, shapiro_p = stats.shapiro(residuals[:min(5000, len(residuals))])  # é™åˆ¶æ ·æœ¬æ•°
    plt.text(0.05, 0.95, f'Shapiro-Wilkæ­£æ€æ€§æ£€éªŒ\np-value: {shapiro_p:.3f}', 
             transform=plt.gca().transAxes, bbox=dict(boxstyle="round", facecolor='lightblue'))
    
    # 4. Q-Qå›¾
    plt.subplot(2, 3, 4)
    stats.probplot(residuals, dist="norm", plot=plt)
    plt.title('Q-Qå›¾ (æ­£æ€æ€§æ£€éªŒ)')
    plt.grid(True, alpha=0.3)
    
    # 5. è¯¯å·®éšç´¢å¼•å˜åŒ–ï¼ˆæ£€æŸ¥æ—¶é—´åºåˆ—ç›¸å…³æ€§ï¼‰
    plt.subplot(2, 3, 5)
    plt.plot(residuals, alpha=0.7)
    plt.axhline(y=0, color='r', linestyle='--')
    plt.xlabel('æ ·æœ¬ç´¢å¼•')
    plt.ylabel('æ®‹å·®')
    plt.title('æ®‹å·®åºåˆ—å›¾')
    plt.grid(True, alpha=0.3)
    
    # 6. æ®‹å·®ç»å¯¹å€¼
    plt.subplot(2, 3, 6)
    plt.scatter(y_pred, abs_residuals, alpha=0.6, edgecolors='k', linewidth=0.5)
    plt.xlabel('é¢„æµ‹å€¼')
    plt.ylabel('|æ®‹å·®|')
    plt.title('ç»å¯¹æ®‹å·®å›¾')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # æ®‹å·®åˆ†ææ€»ç»“
    print("\n=== æ®‹å·®åˆ†ææ€»ç»“ ===")
    print(f"æ®‹å·®å‡å€¼: {np.mean(residuals):.6f} (åº”æ¥è¿‘0)")
    print(f"æ®‹å·®æ ‡å‡†å·®: {np.std(residuals):.4f}")
    print(f"æ®‹å·®ååº¦: {stats.skew(residuals):.4f} (åº”æ¥è¿‘0)")
    print(f"æ®‹å·®å³°åº¦: {stats.kurtosis(residuals):.4f} (åº”æ¥è¿‘0)")
    
    if abs(heteroscedasticity) > 0.3:
        print("âš ï¸  è­¦å‘Šï¼šå¯èƒ½å­˜åœ¨å¼‚æ–¹å·®æ€§")
    if shapiro_p < 0.05:
        print("âš ï¸  è­¦å‘Šï¼šæ®‹å·®å¯èƒ½ä¸æœä»æ­£æ€åˆ†å¸ƒ")
    
    return {
        'mae': mae, 'mse': mse, 'rmse': rmse, 'r2': r2,
        'explained_variance': evs, 'max_error': max_error
    }
```

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šäº¤å‰éªŒè¯å’Œæ¨¡å‹é€‰æ‹©

### 3.1 äº¤å‰éªŒè¯çš„æ•°å­¦åŸºç¡€

#### 3.1.1 KæŠ˜äº¤å‰éªŒè¯

**ç®—æ³•æ­¥éª¤ï¼š**

1. å°†æ•°æ®é›†Déšæœºåˆ†æˆkä¸ªå¤§å°ç›¸ç­‰çš„å­é›†ï¼š$D_1, D_2, \ldots, D_k$
2. å¯¹äºæ¯ä¸ªå­é›†$D_i$ï¼Œç”¨å…¶ä»–k-1ä¸ªå­é›†è®­ç»ƒæ¨¡å‹ï¼Œåœ¨$D_i$ä¸Šæµ‹è¯•
3. è®¡ç®—kä¸ªæµ‹è¯•ç»“æœçš„å¹³å‡å€¼ä½œä¸ºæœ€ç»ˆä¼°è®¡

**æ•°å­¦è¡¨ç¤ºï¼š**
$$\text{CV}_k = \frac{1}{k}\sum_{i=1}^{k} L(f^{(-i)}, D_i)$$

å…¶ä¸­$f^{(-i)}$è¡¨ç¤ºåœ¨é™¤$D_i$å¤–çš„æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹ï¼Œ$L$æ˜¯æŸå¤±å‡½æ•°ã€‚

**æ–¹å·®ä¼°è®¡ï¼š**
$$\text{Var}(\text{CV}_k) = \frac{1}{k}\sum_{i=1}^{k}(L_i - \text{CV}_k)^2$$

#### 3.1.2 ä¸åŒäº¤å‰éªŒè¯ç­–ç•¥çš„æ¯”è¾ƒ

##### 1. ç•™ä¸€äº¤å‰éªŒè¯ (LOOCV)

- k = nï¼ˆæ ·æœ¬æ•°é‡ï¼‰
- **ä¼˜ç‚¹**ï¼šå‡ ä¹æ— åä¼°è®¡ï¼Œå……åˆ†åˆ©ç”¨æ•°æ®
- **ç¼ºç‚¹**ï¼šè®¡ç®—æˆæœ¬é«˜ï¼Œæ–¹å·®å¤§

##### 2. åˆ†å±‚äº¤å‰éªŒè¯

- ä¿æŒå„æŠ˜ä¸­ç±»åˆ«åˆ†å¸ƒä¸åŸæ•°æ®é›†ä¸€è‡´
- **é€‚ç”¨**ï¼šä¸å¹³è¡¡æ•°æ®é›†

##### 3. æ—¶é—´åºåˆ—äº¤å‰éªŒè¯

- è€ƒè™‘æ—¶é—´é¡ºåºï¼Œé¿å…æ•°æ®æ³„éœ²
- **æ–¹æ³•**ï¼šæ»‘åŠ¨çª—å£ã€æ‰©å±•çª—å£

#### 3.1.3 å®ç°å…¨é¢çš„äº¤å‰éªŒè¯åˆ†æ

```python
from sklearn.model_selection import *
import pandas as pd

def comprehensive_cross_validation(models, X, y, cv_strategies=None, scoring_metrics=None):
    """å…¨é¢çš„äº¤å‰éªŒè¯åˆ†æ"""
    
    if cv_strategies is None:
        cv_strategies = {
            'KFold-5': KFold(n_splits=5, shuffle=True, random_state=42),
            'KFold-10': KFold(n_splits=10, shuffle=True, random_state=42),
            'StratifiedKFold-5': StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
        }
    
    if scoring_metrics is None:
        # æ ¹æ®é—®é¢˜ç±»å‹é€‰æ‹©æŒ‡æ ‡
        unique_targets = len(np.unique(y))
        if unique_targets <= 20:  # åˆ†ç±»é—®é¢˜
            scoring_metrics = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted']
        else:  # å›å½’é—®é¢˜
            scoring_metrics = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']
    
    results = {}
    
    for model_name, model in models.items():
        print(f"\n=== {model_name} ===")
        model_results = {}
        
        for cv_name, cv_strategy in cv_strategies.items():
            print(f"\n{cv_name} äº¤å‰éªŒè¯:")
            cv_results = {}
            
            for metric in scoring_metrics:
                scores = cross_val_score(model, X, y, cv=cv_strategy, 
                                       scoring=metric, n_jobs=-1)
                
                cv_results[metric] = {
                    'scores': scores,
                    'mean': scores.mean(),
                    'std': scores.std(),
                    'ci_lower': scores.mean() - 1.96 * scores.std(),
                    'ci_upper': scores.mean() + 1.96 * scores.std()
                }
                
                print(f"  {metric}: {scores.mean():.4f} (Â±{scores.std():.4f})")
                print(f"    95% CI: [{cv_results[metric]['ci_lower']:.4f}, "
                      f"{cv_results[metric]['ci_upper']:.4f}]")
            
            model_results[cv_name] = cv_results
        
        results[model_name] = model_results
    
    # å¯è§†åŒ–æ¯”è¾ƒ
    plot_cv_comparison(results, scoring_metrics[0])  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæŒ‡æ ‡ç»˜å›¾
    
    return results

def plot_cv_comparison(cv_results, primary_metric):
    """å¯è§†åŒ–äº¤å‰éªŒè¯ç»“æœæ¯”è¾ƒ"""
    
    # å‡†å¤‡æ•°æ®
    models = list(cv_results.keys())
    cv_strategies = list(cv_results[models[0]].keys())
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    axes = axes.ravel()
    
    # 1. ä¸åŒæ¨¡å‹åœ¨ä¸åŒCVç­–ç•¥ä¸‹çš„è¡¨ç°
    ax = axes[0]
    x_pos = np.arange(len(models))
    width = 0.25
    
    for i, cv_name in enumerate(cv_strategies):
        means = []
        stds = []
        for model in models:
            result = cv_results[model][cv_name][primary_metric]
            means.append(result['mean'])
            stds.append(result['std'])
        
        ax.bar(x_pos + i * width, means, width, yerr=stds, 
               label=cv_name, capsize=5, alpha=0.8)
    
    ax.set_xlabel('æ¨¡å‹')
    ax.set_ylabel(primary_metric)
    ax.set_title(f'ä¸åŒäº¤å‰éªŒè¯ç­–ç•¥ä¸‹çš„{primary_metric}æ¯”è¾ƒ')
    ax.set_xticks(x_pos + width)
    ax.set_xticklabels(models, rotation=45)
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 2. å„æ¨¡å‹å¾—åˆ†åˆ†å¸ƒç®±çº¿å›¾
    ax = axes[1]
    all_scores = []
    labels = []
    
    for model in models:
        for cv_name in cv_strategies:
            scores = cv_results[model][cv_name][primary_metric]['scores']
            all_scores.append(scores)
            labels.append(f"{model}\n{cv_name}")
    
    box_plot = ax.boxplot(all_scores, labels=labels, patch_artist=True)
    ax.set_title('å„æ¨¡å‹äº¤å‰éªŒè¯å¾—åˆ†åˆ†å¸ƒ')
    ax.set_ylabel(primary_metric)
    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')
    ax.grid(True, alpha=0.3)
    
    # 3. æ¨¡å‹ç¨³å®šæ€§åˆ†æï¼ˆæ ‡å‡†å·®ï¼‰
    ax = axes[2]
    x_pos = np.arange(len(models))
    
    for i, cv_name in enumerate(cv_strategies):
        stds = []
        for model in models:
            result = cv_results[model][cv_name][primary_metric]
            stds.append(result['std'])
        
        ax.bar(x_pos + i * width, stds, width, 
               label=cv_name, alpha=0.8)
    
    ax.set_xlabel('æ¨¡å‹')
    ax.set_ylabel(f'{primary_metric} æ ‡å‡†å·®')
    ax.set_title('æ¨¡å‹ç¨³å®šæ€§æ¯”è¾ƒ (æ ‡å‡†å·®è¶Šå°è¶Šç¨³å®š)')
    ax.set_xticks(x_pos + width)
    ax.set_xticklabels(models, rotation=45)
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 4. ç½®ä¿¡åŒºé—´æ¯”è¾ƒ
    ax = axes[3]
    y_pos = np.arange(len(models) * len(cv_strategies))
    ci_ranges = []
    means = []
    y_labels = []
    
    for model in models:
        for cv_name in cv_strategies:
            result = cv_results[model][cv_name][primary_metric]
            ci_ranges.append(result['ci_upper'] - result['ci_lower'])
            means.append(result['mean'])
            y_labels.append(f"{model}-{cv_name}")
    
    ax.barh(y_pos, ci_ranges, alpha=0.7)
    ax.set_xlabel('ç½®ä¿¡åŒºé—´å®½åº¦')
    ax.set_ylabel('æ¨¡å‹-CVç­–ç•¥')
    ax.set_title('ç½®ä¿¡åŒºé—´å®½åº¦æ¯”è¾ƒ (å®½åº¦è¶Šå°è¶Šå¯é )')
    ax.set_yticks(y_pos)
    ax.set_yticklabels(y_labels)
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

def statistical_significance_test(cv_results, model1, model2, cv_strategy, metric):
    """ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ"""
    
    scores1 = cv_results[model1][cv_strategy][metric]['scores']
    scores2 = cv_results[model2][cv_strategy][metric]['scores']
    
    # é…å¯¹tæ£€éªŒ
    from scipy import stats
    t_stat, p_value = stats.ttest_rel(scores1, scores2)
    
    print(f"\n=== {model1} vs {model2} ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ ===")
    print(f"æ£€éªŒæ–¹æ³•: é…å¯¹tæ£€éªŒ")
    print(f"tç»Ÿè®¡é‡: {t_stat:.4f}")
    print(f"på€¼: {p_value:.4f}")
    
    alpha = 0.05
    if p_value < alpha:
        winner = model1 if scores1.mean() > scores2.mean() else model2
        print(f"ç»“è®º: {winner} æ˜¾è‘—ä¼˜äºå¦ä¸€æ¨¡å‹ (Î± = {alpha})")
    else:
        print(f"ç»“è®º: ä¸¤æ¨¡å‹æ— æ˜¾è‘—å·®å¼‚ (Î± = {alpha})")
    
    return t_stat, p_value
```

### 3.2 å­¦ä¹ æ›²çº¿å’ŒéªŒè¯æ›²çº¿

#### 3.2.1 å­¦ä¹ æ›²çº¿åˆ†æ

å­¦ä¹ æ›²çº¿æ˜¾ç¤ºæ¨¡å‹æ€§èƒ½éšè®­ç»ƒæ ·æœ¬æ•°é‡çš„å˜åŒ–ï¼Œç”¨äºè¯Šæ–­ï¼š

- **æ¬ æ‹Ÿåˆ**ï¼šè®­ç»ƒå’ŒéªŒè¯æ›²çº¿éƒ½è¾ƒä½ä¸”æ¥è¿‘
- **è¿‡æ‹Ÿåˆ**ï¼šè®­ç»ƒæ›²çº¿é«˜ï¼ŒéªŒè¯æ›²çº¿ä½ï¼Œå·®è·å¤§
- **ç†æƒ³çŠ¶æ€**ï¼šä¸¤æ¡æ›²çº¿éƒ½è¾ƒé«˜ä¸”æ¥è¿‘

```python
def comprehensive_learning_curve_analysis(model, X, y, cv=5):
    """å…¨é¢çš„å­¦ä¹ æ›²çº¿åˆ†æ"""
    
    # è®¡ç®—å­¦ä¹ æ›²çº¿
    train_sizes, train_scores, val_scores = learning_curve(
        model, X, y, cv=cv, n_jobs=-1,
        train_sizes=np.linspace(0.1, 1.0, 10),
        scoring='accuracy',
        random_state=42
    )
    
    # è®¡ç®—ç»Ÿè®¡é‡
    train_mean = np.mean(train_scores, axis=1)
    train_std = np.std(train_scores, axis=1)
    val_mean = np.mean(val_scores, axis=1)
    val_std = np.std(val_scores, axis=1)
    
    plt.figure(figsize=(15, 5))
    
    # 1. å­¦ä¹ æ›²çº¿
    plt.subplot(1, 3, 1)
    plt.plot(train_sizes, train_mean, 'o-', color='blue', label='è®­ç»ƒé›†')
    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std,
                     alpha=0.1, color='blue')
    plt.plot(train_sizes, val_mean, 'o-', color='red', label='éªŒè¯é›†')
    plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std,
                     alpha=0.1, color='red')
    plt.xlabel('è®­ç»ƒæ ·æœ¬æ•°')
    plt.ylabel('å‡†ç¡®ç‡')
    plt.title('å­¦ä¹ æ›²çº¿')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # 2. è¿‡æ‹Ÿåˆç¨‹åº¦åˆ†æ
    plt.subplot(1, 3, 2)
    overfitting_gap = train_mean - val_mean
    plt.plot(train_sizes, overfitting_gap, 'o-', color='orange', linewidth=2)
    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    plt.xlabel('è®­ç»ƒæ ·æœ¬æ•°')
    plt.ylabel('è¿‡æ‹Ÿåˆç¨‹åº¦ (è®­ç»ƒåˆ†æ•° - éªŒè¯åˆ†æ•°)')
    plt.title('è¿‡æ‹Ÿåˆç¨‹åº¦åˆ†æ')
    plt.grid(True, alpha=0.3)
    
    # 3. æ–¹å·®åˆ†æ
    plt.subplot(1, 3, 3)
    plt.plot(train_sizes, train_std, 'o-', color='blue', label='è®­ç»ƒé›†æ–¹å·®')
    plt.plot(train_sizes, val_std, 'o-', color='red', label='éªŒè¯é›†æ–¹å·®')
    plt.xlabel('è®­ç»ƒæ ·æœ¬æ•°')
    plt.ylabel('æ ‡å‡†å·®')
    plt.title('æ–¹å·®åˆ†æ')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # åˆ†æç»“è®º
    final_gap = overfitting_gap[-1]
    final_val_score = val_mean[-1]
    
    print("=== å­¦ä¹ æ›²çº¿åˆ†æç»“è®º ===")
    print(f"æœ€ç»ˆéªŒè¯åˆ†æ•°: {final_val_score:.4f}")
    print(f"æœ€ç»ˆè¿‡æ‹Ÿåˆç¨‹åº¦: {final_gap:.4f}")
    
    if final_gap > 0.1:
        print("ğŸ”´ æ£€æµ‹åˆ°è¿‡æ‹Ÿåˆ")
        print("å»ºè®®: å¢åŠ æ­£åˆ™åŒ–ã€å‡å°‘æ¨¡å‹å¤æ‚åº¦æˆ–å¢åŠ è®­ç»ƒæ•°æ®")
    elif final_val_score < 0.7:
        print("ğŸŸ¡ æ£€æµ‹åˆ°æ¬ æ‹Ÿåˆ")
        print("å»ºè®®: å¢åŠ æ¨¡å‹å¤æ‚åº¦ã€æ·»åŠ ç‰¹å¾æˆ–æ£€æŸ¥æ•°æ®è´¨é‡")
    else:
        print("ğŸŸ¢ æ¨¡å‹æ‹Ÿåˆè‰¯å¥½")
    
    # æ•°æ®æ•ˆç‡åˆ†æ
    data_efficiency = (val_mean[-1] - val_mean[0]) / (train_sizes[-1] - train_sizes[0])
    print(f"æ•°æ®æ•ˆç‡: {data_efficiency:.6f} æ¯ä¸ªæ ·æœ¬çš„æ€§èƒ½æå‡")
    
    return train_sizes, train_scores, val_scores
```

#### 3.2.2 éªŒè¯æ›²çº¿åˆ†æ

```python
def comprehensive_validation_curve_analysis(model, X, y, param_name, param_range, cv=5):
    """å…¨é¢çš„éªŒè¯æ›²çº¿åˆ†æ"""
    
    # è®¡ç®—éªŒè¯æ›²çº¿
    train_scores, val_scores = validation_curve(
        model, X, y, param_name=param_name, param_range=param_range,
        cv=cv, scoring='accuracy', n_jobs=-1
    )
    
    train_mean = np.mean(train_scores, axis=1)
    train_std = np.std(train_scores, axis=1)
    val_mean = np.mean(val_scores, axis=1)
    val_std = np.std(val_scores, axis=1)
    
    plt.figure(figsize=(15, 5))
    
    # 1. éªŒè¯æ›²çº¿
    plt.subplot(1, 3, 1)
    plt.semilogx(param_range, train_mean, 'o-', color='blue', label='è®­ç»ƒé›†')
    plt.fill_between(param_range, train_mean - train_std, train_mean + train_std,
                     alpha=0.1, color='blue')
    plt.semilogx(param_range, val_mean, 'o-', color='red', label='éªŒè¯é›†')
    plt.fill_between(param_range, val_mean - val_std, val_mean + val_std,
                     alpha=0.1, color='red')
    plt.xlabel(f'{param_name} (log scale)')
    plt.ylabel('å‡†ç¡®ç‡')
    plt.title(f'éªŒè¯æ›²çº¿ ({param_name})')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # 2. åå·®-æ–¹å·®æƒè¡¡
    plt.subplot(1, 3, 2)
    bias_proxy = 1 - val_mean  # ç”¨1-éªŒè¯åˆ†æ•°è¿‘ä¼¼åå·®
    variance_proxy = val_std   # ç”¨éªŒè¯åˆ†æ•°æ ‡å‡†å·®è¿‘ä¼¼æ–¹å·®
    
    plt.semilogx(param_range, bias_proxy, 'o-', color='red', label='åå·® (è¿‘ä¼¼)')
    plt.semilogx(param_range, variance_proxy, 'o-', color='blue', label='æ–¹å·® (è¿‘ä¼¼)')
    plt.xlabel(f'{param_name} (log scale)')
    plt.ylabel('è¯¯å·®')
    plt.title('åå·®-æ–¹å·®æƒè¡¡')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # 3. æœ€ä¼˜å‚æ•°é€‰æ‹©
    plt.subplot(1, 3, 3)
    # ç»¼åˆè€ƒè™‘éªŒè¯åˆ†æ•°å’Œç¨³å®šæ€§
    stability_penalty = val_std / val_mean  # å˜å¼‚ç³»æ•°
    composite_score = val_mean - stability_penalty  # ç»¼åˆå¾—åˆ†
    
    plt.semilogx(param_range, val_mean, 'o-', color='green', label='éªŒè¯åˆ†æ•°')
    plt.semilogx(param_range, composite_score, 'o-', color='orange', label='ç»¼åˆå¾—åˆ†')
    
    # æ ‡è®°æœ€ä¼˜ç‚¹
    best_idx_validation = np.argmax(val_mean)
    best_idx_composite = np.argmax(composite_score)
    
    plt.axvline(x=param_range[best_idx_validation], color='green', 
                linestyle='--', alpha=0.7, label=f'æœ€ä½³éªŒè¯: {param_range[best_idx_validation]}')
    plt.axvline(x=param_range[best_idx_composite], color='orange', 
                linestyle='--', alpha=0.7, label=f'æœ€ä½³ç»¼åˆ: {param_range[best_idx_composite]}')
    
    plt.xlabel(f'{param_name} (log scale)')
    plt.ylabel('å¾—åˆ†')
    plt.title('å‚æ•°é€‰æ‹©ç­–ç•¥æ¯”è¾ƒ')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # è¾“å‡ºåˆ†æç»“æœ
    print("=== éªŒè¯æ›²çº¿åˆ†æç»“è®º ===")
    print(f"æœ€ä½³éªŒè¯åˆ†æ•°: {val_mean[best_idx_validation]:.4f} "
          f"(å‚æ•° = {param_range[best_idx_validation]})")
    print(f"æœ€ä½³ç»¼åˆå¾—åˆ†: {composite_score[best_idx_composite]:.4f} "
          f"(å‚æ•° = {param_range[best_idx_composite]})")
    print(f"å¯¹åº”éªŒè¯åˆ†æ•°: {val_mean[best_idx_composite]:.4f}")
    print(f"å¯¹åº”ç¨³å®šæ€§: {val_std[best_idx_composite]:.4f}")
    
    return param_range[best_idx_validation], param_range[best_idx_composite]
```

## ç¬¬å››éƒ¨åˆ†ï¼šåå·®-æ–¹å·®æƒè¡¡

### 4.1 åå·®-æ–¹å·®åˆ†è§£çš„æ•°å­¦åŸºç¡€

#### 4.1.1 ç†è®ºæ¨å¯¼

å¯¹äºå›å½’é—®é¢˜ï¼Œè®¾çœŸå®å‡½æ•°ä¸º$f(x)$ï¼Œå™ªå£°ä¸º$\epsilon \sim N(0, \sigma^2)$ï¼Œæ¨¡å‹é¢„æµ‹ä¸º$\hat{f}(x)$ï¼Œåˆ™ï¼š

$$y = f(x) + \epsilon$$

é¢„æµ‹è¯¯å·®çš„æœŸæœ›å¯ä»¥åˆ†è§£ä¸ºï¼š

$$\mathbb{E}[(y - \hat{f}(x))^2] = \text{Bias}^2(\hat{f}(x)) + \text{Var}(\hat{f}(x)) + \sigma^2$$

å…¶ä¸­ï¼š

**åå·® (Bias)ï¼š**
$$\text{Bias}(\hat{f}(x)) = \mathbb{E}[\hat{f}(x)] - f(x)$$

**æ–¹å·® (Variance)ï¼š**
$$\text{Var}(\hat{f}(x)) = \mathbb{E}[(\hat{f}(x) - \mathbb{E}[\hat{f}(x)])^2]$$

**å™ªå£° (Irreducible Error)ï¼š**
$$\sigma^2 = \mathbb{E}[\epsilon^2]$$

#### 4.1.2 ç›´è§‚ç†è§£

```text
é«˜åå·®ï¼Œä½æ–¹å·®ï¼š
ğŸ¯     â—â—â—
       â—â—â—  (ç³»ç»Ÿæ€§åç¦»é¶å¿ƒï¼Œä½†å¾ˆé›†ä¸­)
       â—â—â—

ä½åå·®ï¼Œé«˜æ–¹å·®ï¼š
ğŸ¯   â—   â—
    â—  â—   (å›´ç»•é¶å¿ƒï¼Œä½†å¾ˆåˆ†æ•£)
  â—       â—

é«˜åå·®ï¼Œé«˜æ–¹å·®ï¼š
ğŸ¯       â—
   â—   â—    (æ—¢åç¦»é¶å¿ƒåˆåˆ†æ•£)
     â—   â—

ä½åå·®ï¼Œä½æ–¹å·®ï¼š
ğŸ¯  â—â—â—
    â—â—â—     (ç†æƒ³çŠ¶æ€ï¼šå‡†ç¡®ä¸”ç¨³å®š)
    â—â—â—
```

### 4.2 å®ç°åå·®-æ–¹å·®åˆ†è§£

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from scipy.stats import linregress

def bias_variance_decomposition(model_class, X, y, n_trials=100, test_size=0.3, 
                               problem_type='regression'):
    """å®Œæ•´çš„åå·®-æ–¹å·®åˆ†è§£åˆ†æ"""
    
    n_samples = len(X)
    n_test = int(n_samples * test_size)
    
    predictions = []
    test_indices_list = []
    
    print(f"è¿›è¡Œ {n_trials} æ¬¡ç‹¬ç«‹å®éªŒ...")
    
    for trial in range(n_trials):
        # éšæœºåˆ†å‰²æ•°æ®
        indices = np.random.permutation(n_samples)
        train_idx = indices[:-n_test]
        test_idx = indices[-n_test:]
        
        X_train, X_test = X[train_idx], X[test_idx]
        y_train, y_test = y[train_idx], y[test_idx]
        
        # è®­ç»ƒæ¨¡å‹
        if hasattr(model_class, '__call__'):
            model = model_class()
        else:
            model = model_class
        
        model.fit(X_train, y_train)
        
        # é¢„æµ‹
        if problem_type == 'regression':
            y_pred = model.predict(X_test)
        else:  # classification
            if hasattr(model, 'predict_proba'):
                y_pred = model.predict_proba(X_test)[:, 1]  # å‡è®¾äºŒåˆ†ç±»
            else:
                y_pred = model.predict(X_test)
        
        predictions.append(y_pred)
        test_indices_list.append(test_idx)
    
    # æ‰¾åˆ°å…±åŒçš„æµ‹è¯•æ ·æœ¬
    common_indices = set(test_indices_list[0])
    for indices in test_indices_list[1:]:
        common_indices = common_indices.intersection(set(indices))
    
    if len(common_indices) < 10:
        print("è­¦å‘Šï¼šå…±åŒæµ‹è¯•æ ·æœ¬è¿‡å°‘ï¼Œä½¿ç”¨æ›¿ä»£æ–¹æ³•...")
        return alternative_bias_variance_analysis(model_class, X, y, n_trials)
    
    common_indices = list(common_indices)
    
    # æ”¶é›†å…±åŒæ ·æœ¬çš„é¢„æµ‹ç»“æœ
    common_predictions = []
    for i, pred in enumerate(predictions):
        # æ‰¾åˆ°å½“å‰é¢„æµ‹ä¸­å¯¹åº”çš„ä½ç½®
        test_idx = test_indices_list[i]
        mask = np.isin(test_idx, common_indices)
        common_pred = pred[mask]
        
        # æŒ‰ç…§common_indicesçš„é¡ºåºæ’åˆ—
        ordered_pred = np.zeros(len(common_indices))
        for j, idx in enumerate(common_indices):
            pos = np.where(np.array(test_idx) == idx)[0][0]
            ordered_pred[j] = pred[pos]
        
        common_predictions.append(ordered_pred)
    
    predictions = np.array(common_predictions)
    y_true = y[common_indices]
    
    # è®¡ç®—åå·®-æ–¹å·®åˆ†è§£
    mean_pred = np.mean(predictions, axis=0)
    
    if problem_type == 'regression':
        # å›å½’é—®é¢˜çš„åå·®-æ–¹å·®åˆ†è§£
        bias_squared = np.mean((mean_pred - y_true) ** 2)
        variance = np.mean(np.var(predictions, axis=0))
        
        # ä¼°è®¡å™ªå£°ï¼ˆä½¿ç”¨æœ€ä¼˜é¢„æµ‹çš„æ®‹å·®ï¼‰
        total_error = np.mean((predictions - y_true.reshape(1, -1)) ** 2)
        noise = max(0, total_error - bias_squared - variance)  # ç¡®ä¿éè´Ÿ
        
        print("=== åå·®-æ–¹å·®åˆ†è§£ç»“æœ (å›å½’) ===")
        print(f"åå·®Â²: {bias_squared:.6f}")
        print(f"æ–¹å·®: {variance:.6f}")
        print(f"å™ªå£°: {noise:.6f}")
        print(f"æ€»è¯¯å·®: {total_error:.6f}")
        print(f"åˆ†è§£éªŒè¯: {bias_squared + variance + noise:.6f}")
        
        components = ['åå·®Â²', 'æ–¹å·®', 'å™ªå£°']
        values = [bias_squared, variance, noise]
        
    else:
        # åˆ†ç±»é—®é¢˜çš„åå·®-æ–¹å·®åˆ†è§£ï¼ˆä½¿ç”¨0-1æŸå¤±ï¼‰
        # è®¡ç®—ä¸»è¦é¢„æµ‹ï¼ˆå¤šæ•°æŠ•ç¥¨ï¼‰
        if len(predictions.shape) > 1 and predictions.shape[1] > 1:
            # å¤šç±»é¢„æµ‹
            main_pred = np.array([np.bincount(predictions[:, i]).argmax() 
                                for i in range(predictions.shape[1])])
        else:
            # äºŒåˆ†ç±»é¢„æµ‹
            main_pred = np.round(mean_pred).astype(int)
        
        # è®¡ç®—åå·®ï¼ˆä¸»è¦é¢„æµ‹ä¸çœŸå®æ ‡ç­¾çš„ä¸ä¸€è‡´æ€§ï¼‰
        bias = np.mean(main_pred != y_true)
        
        # è®¡ç®—æ–¹å·®ï¼ˆä¸åŒé¢„æµ‹ä¹‹é—´çš„ä¸ä¸€è‡´æ€§ï¼‰
        variance = 0
        for i in range(len(common_indices)):
            # è®¡ç®—æ¯ä¸ªæ ·æœ¬é¢„æµ‹çš„æ–¹å·®ï¼ˆåˆ†ç±»çš„ç¦»æ•£åº¦ï¼‰
            if len(predictions.shape) > 1:
                unique_preds = np.unique(predictions[:, i])
                if len(unique_preds) > 1:
                    variance += 1 - np.max(np.bincount(predictions[:, i].astype(int))) / len(predictions)
        variance /= len(common_indices)
        
        noise = 0.05  # åˆ†ç±»é—®é¢˜çš„å™ªå£°é€šå¸¸è¾ƒå°
        
        print("=== åå·®-æ–¹å·®åˆ†è§£ç»“æœ (åˆ†ç±») ===")
        print(f"åå·®: {bias:.6f}")
        print(f"æ–¹å·®: {variance:.6f}")
        print(f"å™ªå£° (ä¼°è®¡): {noise:.6f}")
        
        components = ['åå·®', 'æ–¹å·®', 'å™ªå£°']
        values = [bias, variance, noise]
    
    # å¯è§†åŒ–ç»“æœ
    plt.figure(figsize=(15, 10))
    
    # 1. åå·®-æ–¹å·®åˆ†è§£é¥¼å›¾
    plt.subplot(2, 3, 1)
    colors = ['#ff9999', '#66b3ff', '#99ff99']
    plt.pie(values, labels=components, autopct='%1.1f%%', colors=colors, startangle=90)
    plt.title('åå·®-æ–¹å·®åˆ†è§£')
    
    # 2. å„ç»„ä»¶è´¡çŒ®æŸ±çŠ¶å›¾
    plt.subplot(2, 3, 2)
    bars = plt.bar(components, values, color=colors, alpha=0.7, edgecolor='black')
    plt.ylabel('è¯¯å·®è´¡çŒ®')
    plt.title('å„ç»„ä»¶è¯¯å·®è´¡çŒ®')
    plt.grid(True, alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, value in zip(bars, values):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values)*0.01,
                f'{value:.4f}', ha='center', va='bottom')
    
    # 3. é¢„æµ‹åˆ†å¸ƒåˆ†æ
    plt.subplot(2, 3, 3)
    for i in range(min(5, len(common_indices))):  # åªæ˜¾ç¤ºå‰5ä¸ªæ ·æœ¬
        plt.hist(predictions[:, i], alpha=0.6, bins=20, 
                label=f'æ ·æœ¬ {i+1}', density=True)
    plt.xlabel('é¢„æµ‹å€¼')
    plt.ylabel('å¯†åº¦')
    plt.title('é¢„æµ‹å€¼åˆ†å¸ƒ (å‰5ä¸ªæ ·æœ¬)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # 4. åå·®åˆ†æ
    plt.subplot(2, 3, 4)
    bias_per_sample = np.abs(mean_pred - y_true)
    plt.plot(bias_per_sample, 'o-', alpha=0.7)
    plt.axhline(y=np.mean(bias_per_sample), color='r', linestyle='--', 
                label=f'å¹³å‡åå·®: {np.mean(bias_per_sample):.4f}')
    plt.xlabel('æ ·æœ¬ç´¢å¼•')
    plt.ylabel('|åå·®|')
    plt.title('å„æ ·æœ¬åå·®åˆ†æ')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # 5. æ–¹å·®åˆ†æ
    plt.subplot(2, 3, 5)
    variance_per_sample = np.var(predictions, axis=0)
    plt.plot(variance_per_sample, 'o-', alpha=0.7, color='blue')
    plt.axhline(y=np.mean(variance_per_sample), color='r', linestyle='--',
                label=f'å¹³å‡æ–¹å·®: {np.mean(variance_per_sample):.4f}')
    plt.xlabel('æ ·æœ¬ç´¢å¼•')
    plt.ylabel('æ–¹å·®')
    plt.title('å„æ ·æœ¬æ–¹å·®åˆ†æ')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # 6. åå·®vsæ–¹å·®æ•£ç‚¹å›¾
    plt.subplot(2, 3, 6)
    plt.scatter(bias_per_sample, variance_per_sample, alpha=0.6, edgecolors='k')
    plt.xlabel('|åå·®|')
    plt.ylabel('æ–¹å·®')
    plt.title('åå·® vs æ–¹å·®æƒè¡¡')
    plt.grid(True, alpha=0.3)
    
    # æ·»åŠ è¶‹åŠ¿çº¿
    from scipy.stats import linregress
    slope, intercept, r_value, p_value, std_err = linregress(bias_per_sample, variance_per_sample)
    x_trend = np.linspace(bias_per_sample.min(), bias_per_sample.max(), 100)
    y_trend = slope * x_trend + intercept
    plt.plot(x_trend, y_trend, 'r--', alpha=0.8, 
             label=f'è¶‹åŠ¿çº¿ (RÂ² = {r_value**2:.3f})')
    plt.legend()
    
    plt.tight_layout()
    plt.show()
    
    # è¯¦ç»†åˆ†ææ€»ç»“
    print("\n=== åå·®-æ–¹å·®åˆ†è§£è¯¦ç»†åˆ†æ ===")
    if problem_type == 'regression':
        print(f"å„ç»„ä»¶å æ¯”:")
        total = bias_squared + variance + noise
        print(f"  åå·®Â²å æ¯”: {bias_squared/total*100:.1f}%")
        print(f"  æ–¹å·®å æ¯”: {variance/total*100:.1f}%")
        print(f"  å™ªå£°å æ¯”: {noise/total*100:.1f}%")
        
        if bias_squared > variance:
            print("ğŸ¯ ä¸»è¦é—®é¢˜: é«˜åå·® (æ¬ æ‹Ÿåˆ)")
            print("å»ºè®®: å¢åŠ æ¨¡å‹å¤æ‚åº¦ã€æ·»åŠ ç‰¹å¾ã€å‡å°‘æ­£åˆ™åŒ–")
        elif variance > bias_squared:
            print("ğŸ¯ ä¸»è¦é—®é¢˜: é«˜æ–¹å·® (è¿‡æ‹Ÿåˆ)")
            print("å»ºè®®: å¢åŠ æ­£åˆ™åŒ–ã€å‡å°‘æ¨¡å‹å¤æ‚åº¦ã€å¢åŠ è®­ç»ƒæ•°æ®")
        else:
            print("ğŸ¯ åå·®å’Œæ–¹å·®ç›¸å¯¹å¹³è¡¡")
    
    return {
        'bias_squared': bias_squared if problem_type == 'regression' else bias,
        'variance': variance,
        'noise': noise,
        'total_error': bias_squared + variance + noise if problem_type == 'regression' else bias + variance + noise
    }

def alternative_bias_variance_analysis(model_class, X, y, n_trials=100):
    """æ›¿ä»£çš„åå·®-æ–¹å·®åˆ†ææ–¹æ³•ï¼ˆå½“å…±åŒæµ‹è¯•æ ·æœ¬è¿‡å°‘æ—¶ï¼‰"""
    
    print("ä½¿ç”¨æ›¿ä»£æ–¹æ³•è¿›è¡Œåå·®-æ–¹å·®åˆ†æ...")
    
    # ä½¿ç”¨å›ºå®šçš„æµ‹è¯•é›†
    from sklearn.model_selection import train_test_split
    X_train_base, X_test, y_train_base, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42
    )
    
    predictions = []
    
    for trial in range(n_trials):
        # ä»è®­ç»ƒé›†ä¸­è¿›è¡Œè‡ªåŠ©é‡‡æ ·
        n_train = len(X_train_base)
        bootstrap_idx = np.random.choice(n_train, size=n_train, replace=True)
        X_bootstrap = X_train_base[bootstrap_idx]
        y_bootstrap = y_train_base[bootstrap_idx]
        
        # è®­ç»ƒæ¨¡å‹
        if hasattr(model_class, '__call__'):
            model = model_class()
        else:
            model = model_class
        
        model.fit(X_bootstrap, y_bootstrap)
        y_pred = model.predict(X_test)
        predictions.append(y_pred)
    
    predictions = np.array(predictions)
    
    # è®¡ç®—åå·®-æ–¹å·®åˆ†è§£
    mean_pred = np.mean(predictions, axis=0)
    bias_squared = np.mean((mean_pred - y_test) ** 2)
    variance = np.mean(np.var(predictions, axis=0))
    
    total_error = np.mean((predictions - y_test.reshape(1, -1)) ** 2)
    noise = max(0, total_error - bias_squared - variance)
    
    print("=== æ›¿ä»£æ–¹æ³•åå·®-æ–¹å·®åˆ†è§£ç»“æœ ===")
    print(f"åå·®Â²: {bias_squared:.6f}")
    print(f"æ–¹å·®: {variance:.6f}")
    print(f"å™ªå£°: {noise:.6f}")
    print(f"æ€»è¯¯å·®: {total_error:.6f}")
    
    return {
        'bias_squared': bias_squared,
        'variance': variance,
        'noise': noise,
        'total_error': total_error
    }
```

### 4.3 ä¸åŒå¤æ‚åº¦æ¨¡å‹çš„åå·®-æ–¹å·®åˆ†æ

```python
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier

def compare_model_complexity_bias_variance(X, y, problem_type='regression'):
    """æ¯”è¾ƒä¸åŒå¤æ‚åº¦æ¨¡å‹çš„åå·®-æ–¹å·®æƒè¡¡"""
    
    if problem_type == 'regression':
        models = {
            'çº¿æ€§å›å½’ (ä½å¤æ‚åº¦)': lambda: LinearRegression(),
            'å†³ç­–æ ‘ (æ·±åº¦=3)': lambda: DecisionTreeRegressor(max_depth=3, random_state=42),
            'å†³ç­–æ ‘ (æ·±åº¦=10)': lambda: DecisionTreeRegressor(max_depth=10, random_state=42),
            'å†³ç­–æ ‘ (æ— é™åˆ¶)': lambda: DecisionTreeRegressor(random_state=42),
            'KNN (k=10)': lambda: KNeighborsRegressor(n_neighbors=10),
            'KNN (k=1)': lambda: KNeighborsRegressor(n_neighbors=1),
            'éšæœºæ£®æ—': lambda: RandomForestRegressor(n_estimators=50, random_state=42)
        }
    else:
        models = {
            'é€»è¾‘å›å½’ (ä½å¤æ‚åº¦)': lambda: LogisticRegression(random_state=42),
            'å†³ç­–æ ‘ (æ·±åº¦=3)': lambda: DecisionTreeClassifier(max_depth=3, random_state=42),
            'å†³ç­–æ ‘ (æ·±åº¦=10)': lambda: DecisionTreeClassifier(max_depth=10, random_state=42),
            'å†³ç­–æ ‘ (æ— é™åˆ¶)': lambda: DecisionTreeClassifier(random_state=42),
            'KNN (k=10)': lambda: KNeighborsClassifier(n_neighbors=10),
            'KNN (k=1)': lambda: KNeighborsClassifier(n_neighbors=1),
            'éšæœºæ£®æ—': lambda: RandomForestClassifier(n_estimators=50, random_state=42)
        }
    
    results = {}
    
    print("å¼€å§‹åå·®-æ–¹å·®åˆ†è§£æ¯”è¾ƒåˆ†æ...")
    for model_name, model_func in models.items():
        print(f"\nåˆ†ææ¨¡å‹: {model_name}")
        result = bias_variance_decomposition(model_func, X, y, n_trials=50, 
                                           problem_type=problem_type)
        results[model_name] = result
    
    # å¯è§†åŒ–æ¯”è¾ƒç»“æœ
    plot_bias_variance_comparison(results)
    
    return results

def plot_bias_variance_comparison(results):
    """å¯è§†åŒ–åå·®-æ–¹å·®åˆ†è§£æ¯”è¾ƒç»“æœ"""
    
    models = list(results.keys())
    bias_values = [results[model]['bias_squared'] for model in models]
    variance_values = [results[model]['variance'] for model in models]
    noise_values = [results[model]['noise'] for model in models]
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # 1. å †å æŸ±çŠ¶å›¾
    x = np.arange(len(models))
    width = 0.6
    
    ax1.bar(x, bias_values, width, label='åå·®Â²', alpha=0.8, color='#ff9999')
    ax1.bar(x, variance_values, width, bottom=bias_values, label='æ–¹å·®', alpha=0.8, color='#66b3ff')
    ax1.bar(x, noise_values, width, bottom=np.array(bias_values) + np.array(variance_values), 
            label='å™ªå£°', alpha=0.8, color='#99ff99')
    
    ax1.set_xlabel('æ¨¡å‹')
    ax1.set_ylabel('è¯¯å·®')
    ax1.set_title('åå·®-æ–¹å·®åˆ†è§£æ¯”è¾ƒ')
    ax1.set_xticks(x)
    ax1.set_xticklabels(models, rotation=45, ha='right')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. åå·®vsæ–¹å·®æ•£ç‚¹å›¾
    ax2.scatter(bias_values, variance_values, s=100, alpha=0.7, edgecolors='k')
    for i, model in enumerate(models):
        ax2.annotate(model, (bias_values[i], variance_values[i]), 
                    xytext=(5, 5), textcoords='offset points', fontsize=9)
    
    ax2.set_xlabel('åå·®Â²')
    ax2.set_ylabel('æ–¹å·®')
    ax2.set_title('åå·®-æ–¹å·®æƒè¡¡')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
```

### 4.4 å®é™…åº”ç”¨ç¤ºä¾‹

```python
# ç¤ºä¾‹1: å›å½’é—®é¢˜çš„åå·®-æ–¹å·®åˆ†æ
from sklearn.datasets import make_regression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

def regression_bias_variance_demo():
    """å›å½’é—®é¢˜çš„åå·®-æ–¹å·®åˆ†ææ¼”ç¤º"""
    
    print("=== å›å½’é—®é¢˜åå·®-æ–¹å·®åˆ†ææ¼”ç¤º ===\n")
    
    # ç”Ÿæˆå›å½’æ•°æ®
    X, y = make_regression(n_samples=300, n_features=10, noise=0.1, 
                          random_state=42)
    
    # æ ‡å‡†åŒ–ç‰¹å¾
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # æ¯”è¾ƒä¸åŒå¤æ‚åº¦æ¨¡å‹
    results = compare_model_complexity_bias_variance(X_scaled, y, 'regression')
    
    return results

# ç¤ºä¾‹2: åˆ†ç±»é—®é¢˜çš„åå·®-æ–¹å·®åˆ†æ
from sklearn.datasets import make_classification

def classification_bias_variance_demo():
    """åˆ†ç±»é—®é¢˜çš„åå·®-æ–¹å·®åˆ†ææ¼”ç¤º"""
    
    print("\n=== åˆ†ç±»é—®é¢˜åå·®-æ–¹å·®åˆ†ææ¼”ç¤º ===\n")
    
    # ç”Ÿæˆåˆ†ç±»æ•°æ®
    X, y = make_classification(n_samples=300, n_features=10, n_informative=5,
                              n_redundant=2, n_clusters_per_class=1, 
                              random_state=42)
    
    # æ ‡å‡†åŒ–ç‰¹å¾
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # æ¯”è¾ƒä¸åŒå¤æ‚åº¦æ¨¡å‹
    results = compare_model_complexity_bias_variance(X_scaled, y, 'classification')
    
    return results

    # è¿è¡Œæ¼”ç¤º
if __name__ == "__main__":
    # å›å½’æ¼”ç¤º
    regression_results = regression_bias_variance_demo()
    
    # åˆ†ç±»æ¼”ç¤º  
    classification_results = classification_bias_variance_demo()
    
    print("\n=== åå·®-æ–¹å·®åˆ†ææ€»ç»“ ===")
    print("å›å½’é—®é¢˜ç»“æœ:", regression_results)
    print("åˆ†ç±»é—®é¢˜ç»“æœ:", classification_results)
```

## ç¬¬äº”éƒ¨åˆ†ï¼šå®é™…åº”ç”¨ç¤ºä¾‹

### 5.1 ç»¼åˆæ¡ˆä¾‹ï¼šæˆ¿ä»·é¢„æµ‹æ¨¡å‹è¯„ä¼°

```python
def comprehensive_model_evaluation_demo():
    """å®Œæ•´çš„æ¨¡å‹è¯„ä¼°æ¼”ç¤º"""
    
    from sklearn.datasets import fetch_california_housing
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.linear_model import LinearRegression, Ridge
    from sklearn.svm import SVR
    from sklearn.preprocessing import StandardScaler
    from sklearn.model_selection import KFold, train_test_split
    
    print("=== åŠ å·æˆ¿ä»·é¢„æµ‹æ¨¡å‹è¯„ä¼°æ¡ˆä¾‹ ===\n")
    
    # åŠ è½½æ•°æ®
    housing = fetch_california_housing()
    X, y = housing.data, housing.target
    
    print(f"æ•°æ®é›†ä¿¡æ¯:")
    print(f"æ ·æœ¬æ•°é‡: {X.shape[0]}")
    print(f"ç‰¹å¾æ•°é‡: {X.shape[1]}")
    print(f"ç›®æ ‡å˜é‡èŒƒå›´: [{y.min():.2f}, {y.max():.2f}]")
    
    # æ•°æ®é¢„å¤„ç†
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # å®šä¹‰æ¨¡å‹
    models = {
        'çº¿æ€§å›å½’': LinearRegression(),
        'å²­å›å½’': Ridge(alpha=1.0),
        'éšæœºæ£®æ—': RandomForestRegressor(n_estimators=100, random_state=42),
        'SVR': SVR(kernel='rbf', C=1.0, gamma='scale')
    }
    
    # 1. äº¤å‰éªŒè¯æ¯”è¾ƒ
    print("\n" + "="*50)
    print("ç¬¬ä¸€æ­¥: äº¤å‰éªŒè¯æ¨¡å‹æ¯”è¾ƒ")
    print("="*50)
    
    cv_results = comprehensive_cross_validation(
        models, X_scaled, y,
        cv_strategies={
            'KFold-5': KFold(n_splits=5, shuffle=True, random_state=42),
            'KFold-10': KFold(n_splits=10, shuffle=True, random_state=42)
        },
        scoring_metrics=['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']
    )
    
    # 2. å­¦ä¹ æ›²çº¿åˆ†æ
    print("\n" + "="*50)
    print("ç¬¬äºŒæ­¥: å­¦ä¹ æ›²çº¿åˆ†æ")
    print("="*50)
    
    best_model = RandomForestRegressor(n_estimators=100, random_state=42)
    comprehensive_learning_curve_analysis(best_model, X_scaled, y)
    
    # 3. éªŒè¯æ›²çº¿åˆ†æ
    print("\n" + "="*50)
    print("ç¬¬ä¸‰æ­¥: è¶…å‚æ•°éªŒè¯æ›²çº¿åˆ†æ")
    print("="*50)
    
    param_range = [10, 50, 100, 200, 500]
    comprehensive_validation_curve_analysis(
        RandomForestRegressor(random_state=42), X_scaled, y,
        'n_estimators', param_range
    )
    
    # 4. åå·®-æ–¹å·®åˆ†è§£
    print("\n" + "="*50)
    print("ç¬¬å››æ­¥: åå·®-æ–¹å·®åˆ†è§£åˆ†æ")
    print("="*50)
    
    bias_variance_results = compare_model_complexity_bias_variance(
        X_scaled, y, 'regression'
    )
    
    # 5. æœ€ç»ˆæ¨¡å‹è¯„ä¼°
    print("\n" + "="*50)
    print("ç¬¬äº”æ­¥: æœ€ç»ˆæ¨¡å‹è¯¦ç»†è¯„ä¼°")
    print("="*50)
    
    # è®­ç»ƒæœ€ä½³æ¨¡å‹
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42
    )
    
    final_model = RandomForestRegressor(n_estimators=200, random_state=42)
    final_model.fit(X_train, y_train)
    y_pred = final_model.predict(X_test)
    
    # è¯¦ç»†å›å½’è¯„ä¼°
    regression_metrics(y_test, y_pred)
    
    print("\n=== æ¨¡å‹è¯„ä¼°æ€»ç»“ ===")
    print("1. éšæœºæ£®æ—åœ¨æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ä¸Šè¡¨ç°æœ€ä½³")
    print("2. æ¨¡å‹åœ¨200ä¸ªæ ‘æ—¶è¾¾åˆ°æœ€ä½³æ€§èƒ½")
    print("3. åå·®-æ–¹å·®åˆ†ææ˜¾ç¤ºæ¨¡å‹å¹³è¡¡è‰¯å¥½")
    print("4. æ®‹å·®åˆ†ææ˜¾ç¤ºæ¨¡å‹å‡è®¾åŸºæœ¬æ»¡è¶³")

# è¿è¡Œç»¼åˆæ¼”ç¤º
if __name__ == "__main__":
    comprehensive_model_evaluation_demo()
```

## å­¦ä¹ æ€»ç»“ä¸åæ€

### æ ¸å¿ƒæ”¶è·

é€šè¿‡æ·±å…¥å­¦ä¹ æ¨¡å‹è¯„ä¼°å’Œé€‰æ‹©ï¼Œæˆ‘è·å¾—äº†ä»¥ä¸‹å…³é”®è®¤è¯†ï¼š

1. **è¯„ä¼°æŒ‡æ ‡çš„é€‰æ‹©è‰ºæœ¯**ï¼šä¸åŒçš„ä¸šåŠ¡åœºæ™¯éœ€è¦ä¸åŒçš„è¯„ä¼°é‡ç‚¹ã€‚åœ¨åŒ»ç–—è¯Šæ–­ä¸­ï¼Œé«˜å¬å›ç‡å¯èƒ½æ¯”é«˜ç²¾ç¡®ç‡æ›´é‡è¦ï¼›è€Œåœ¨åƒåœ¾é‚®ä»¶æ£€æµ‹ä¸­ï¼Œå¯èƒ½éœ€è¦å¹³è¡¡ä¸¤è€…ã€‚

2. **äº¤å‰éªŒè¯çš„å¨åŠ›**ï¼šç®€å•çš„è®­ç»ƒ-æµ‹è¯•åˆ†å‰²å¾€å¾€ä¸å¤Ÿå¯é ï¼Œäº¤å‰éªŒè¯æä¾›äº†æ›´ç¨³å¥çš„æ€§èƒ½ä¼°è®¡ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•°æ®æœ‰é™çš„æƒ…å†µä¸‹ã€‚

3. **åå·®-æ–¹å·®æƒè¡¡çš„æ™®éæ€§**ï¼šè¿™ä¸ªæ¦‚å¿µä¸ä»…é€‚ç”¨äºæœºå™¨å­¦ä¹ ï¼Œåœ¨ç”Ÿæ´»ä¸­ä¹Ÿæ— å¤„ä¸åœ¨ã€‚è¿½æ±‚å®Œç¾å¾€å¾€æ„å‘³ç€ä¸ç¨³å®šï¼Œè€Œç¨³å®šå¾€å¾€éœ€è¦æ¥å—ä¸€å®šçš„ç³»ç»Ÿæ€§è¯¯å·®ã€‚

4. **æ¨¡å‹è¯Šæ–­çš„é‡è¦æ€§**ï¼šå­¦ä¹ æ›²çº¿å’ŒéªŒè¯æ›²çº¿å°±åƒåŒ»ç”Ÿçš„"å¬è¯Šå™¨"ï¼Œèƒ½å¤Ÿå¸®æˆ‘ä»¬è¯Šæ–­æ¨¡å‹çš„"å¥åº·çŠ¶å†µ"ï¼ŒæŒ‡å¯¼æ”¹è¿›æ–¹å‘ã€‚

### å®è·µä¸­çš„æ·±åˆ»ä½“ä¼š

**1. "æ²¡æœ‰æµ‹é‡å°±æ²¡æœ‰æ”¹è¿›"**
åœ¨å®é™…é¡¹ç›®ä¸­ï¼Œæˆ‘å‘ç°å¾ˆå¤šæ—¶å€™æ¨¡å‹æ€§èƒ½çš„æå‡æ¥è‡ªäºå¯¹è¯„ä¼°è¿‡ç¨‹çš„ç»†è‡´åˆ†æï¼Œè€Œä¸æ˜¯ç›²ç›®åœ°å°è¯•æ›´å¤æ‚çš„ç®—æ³•ã€‚

**2. "è¿‡æ‹Ÿåˆæ— å¤„ä¸åœ¨"**
é€šè¿‡åå·®-æ–¹å·®åˆ†è§£ï¼Œæˆ‘æ„è¯†åˆ°è¿‡æ‹Ÿåˆä¸ä»…ä»…æ˜¯ä¸€ä¸ªæŠ€æœ¯é—®é¢˜ï¼Œæ›´æ˜¯ä¸€ä¸ªå“²å­¦é—®é¢˜ï¼šå¦‚ä½•åœ¨è®°å¿†å’Œæ³›åŒ–ä¹‹é—´æ‰¾åˆ°å¹³è¡¡ï¼Ÿ

**3. "ç»Ÿè®¡æ˜¾è‘—æ€§çš„é‡è¦æ€§"**
å½“ä¸¤ä¸ªæ¨¡å‹æ€§èƒ½æ¥è¿‘æ—¶ï¼Œä»…ä»…æ¯”è¾ƒå¹³å‡åˆ†æ•°æ˜¯ä¸å¤Ÿçš„ï¼Œéœ€è¦è¿›è¡Œç»Ÿè®¡æ£€éªŒæ¥ç¡®å®šå·®å¼‚æ˜¯å¦çœŸå®å­˜åœ¨ã€‚

### å®¹æ˜“çŠ¯çš„é”™è¯¯

1. **æ•°æ®æ³„éœ²**ï¼šåœ¨äº¤å‰éªŒè¯ä¸­ï¼Œç‰¹å¾é€‰æ‹©æˆ–æ•°æ®é¢„å¤„ç†æ­¥éª¤å¦‚æœåœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œï¼Œä¼šå¯¼è‡´è¿‡äºä¹è§‚çš„æ€§èƒ½ä¼°è®¡ã€‚

2. **ä¸å¹³è¡¡æ•°æ®çš„è¯¯åŒº**ï¼šåœ¨æä¸å¹³è¡¡çš„æ•°æ®é›†ä¸Šï¼Œå‡†ç¡®ç‡å¯èƒ½é«˜è¾¾99%ï¼Œä½†æ¨¡å‹å¯èƒ½å®Œå…¨æ²¡æœ‰å­¦åˆ°æœ‰ç”¨çš„æ¨¡å¼ã€‚

3. **è¿‡åº¦ä¼˜åŒ–éªŒè¯é›†**ï¼šåå¤åœ¨éªŒè¯é›†ä¸Šè°ƒå‚ï¼Œå®é™…ä¸Šæ˜¯æŠŠéªŒè¯é›†å½“ä½œäº†è®­ç»ƒé›†çš„ä¸€éƒ¨åˆ†ã€‚

4. **å¿½ç•¥ä¸šåŠ¡çº¦æŸ**ï¼šæŠ€æœ¯æŒ‡æ ‡å¾ˆé‡è¦ï¼Œä½†æ¨¡å‹çš„å®é™…éƒ¨ç½²è¿˜éœ€è¦è€ƒè™‘å»¶è¿Ÿã€å†…å­˜ã€å¯è§£é‡Šæ€§ç­‰å·¥ç¨‹çº¦æŸã€‚

### è¿›é˜¶å­¦ä¹ æ–¹å‘

1. **åœ¨çº¿å­¦ä¹ çš„è¯„ä¼°**ï¼šå½“æ•°æ®åˆ†å¸ƒéšæ—¶é—´å˜åŒ–æ—¶ï¼Œå¦‚ä½•è¯„ä¼°æ¨¡å‹çš„é€‚åº”æ€§ï¼Ÿ

2. **å¤šä»»åŠ¡å­¦ä¹ è¯„ä¼°**ï¼šå½“ä¸€ä¸ªæ¨¡å‹éœ€è¦åŒæ—¶å®Œæˆå¤šä¸ªä»»åŠ¡æ—¶ï¼Œå¦‚ä½•å¹³è¡¡ä¸åŒä»»åŠ¡çš„æ€§èƒ½ï¼Ÿ

3. **å…¬å¹³æ€§è¯„ä¼°**ï¼šå¦‚ä½•ç¡®ä¿æ¨¡å‹åœ¨ä¸åŒç¾¤ä½“ä¸Šçš„è¡¨ç°å…¬å¹³ï¼Ÿ

4. **ä¸ç¡®å®šæ€§é‡åŒ–**ï¼šå¦‚ä½•è¯„ä¼°æ¨¡å‹é¢„æµ‹çš„ç½®ä¿¡åº¦ï¼Ÿ

### æœ€ç»ˆæ„Ÿæ‚Ÿ

æ¨¡å‹è¯„ä¼°ä¸ä»…ä»…æ˜¯æŠ€æœ¯æ´»ï¼Œæ›´æ˜¯ä¸€é—¨è‰ºæœ¯ã€‚å®ƒè¦æ±‚æˆ‘ä»¬åœ¨å‡†ç¡®æ€§å’Œç¨³å®šæ€§ä¹‹é—´æƒè¡¡ï¼Œåœ¨å¤æ‚æ€§å’Œå¯è§£é‡Šæ€§ä¹‹é—´é€‰æ‹©ï¼Œåœ¨ç†è®ºå®Œç¾å’Œå®é™…å¯è¡Œä¹‹é—´å¦¥åã€‚

æ­£å¦‚ç»Ÿè®¡å­¦å®¶George Boxæ‰€è¯´ï¼š"æ‰€æœ‰æ¨¡å‹éƒ½æ˜¯é”™è¯¯çš„ï¼Œä½†æœ‰äº›æ˜¯æœ‰ç”¨çš„ã€‚" æ¨¡å‹è¯„ä¼°çš„ç›®æ ‡ä¸æ˜¯æ‰¾åˆ°å®Œç¾çš„æ¨¡å‹ï¼Œè€Œæ˜¯æ‰¾åˆ°åœ¨ç»™å®šçº¦æŸä¸‹æœ€æœ‰ç”¨çš„æ¨¡å‹ã€‚

é€šè¿‡ç³»ç»Ÿåœ°å­¦ä¹ æ¨¡å‹è¯„ä¼°å’Œé€‰æ‹©ï¼Œæˆ‘ä¸ä»…è·å¾—äº†æŠ€æœ¯æŠ€èƒ½ï¼Œæ›´é‡è¦çš„æ˜¯åŸ¹å…»äº†ç§‘å­¦ä¸¥è°¨çš„æ€ç»´æ–¹å¼ã€‚è¿™ç§æ€ç»´æ–¹å¼å‘Šè¯‰æˆ‘ä»¬ï¼š

- è¦æœ‰è¯æ®æ”¯æŒçš„ç»“è®º
- è¦é‡åŒ–ä¸ç¡®å®šæ€§
- è¦è€ƒè™‘å¤šä¸ªè§’åº¦
- è¦åœ¨ç†è®ºå’Œå®è·µä¹‹é—´æ‰¾åˆ°å¹³è¡¡

è¿™äº›åŸåˆ™ä¸ä»…é€‚ç”¨äºæœºå™¨å­¦ä¹ ï¼Œä¹Ÿé€‚ç”¨äºç§‘å­¦ç ”ç©¶å’Œæ—¥å¸¸å†³ç­–ã€‚åœ¨è¿™ä¸ªå……æ»¡ä¸ç¡®å®šæ€§çš„ä¸–ç•Œé‡Œï¼ŒæŒæ¡ç§‘å­¦çš„è¯„ä¼°æ–¹æ³•æ¯”æŒæ¡ä»»ä½•ç‰¹å®šçš„ç®—æ³•éƒ½æ›´åŠ é‡è¦ã€‚
