---
title: CUT3R阅读笔记
published: 2025-12-6 00:46:20
slug: cut3r
tags: ['计算机视觉', '3D重建']
category: 计算机视觉
draft: false
---
# CUT3R

![](img/Pasted%20image%2020251204004612.png)

## 摘要

- 一套统一框架 具备持久状态的递归模型 能够持续更新内部状态表征
- 输入一段图像流时，不断演化的状态可以用于在线地生成具有度量尺度的点图 位于全局坐标系中 可以累积为一致，密集的场景重建结果
- 能在虚拟 未观测的视角上进行空间探查 推断出输入中未看到的区域结构
- 简单灵活 可处理任意长度图像输入，支持静态场景和动态场景，能够处理稀疏拍摄，退化相机运动等传统方法难以应对的问题

## 引言

- 本文提出一种**在线 3D 感知框架**，它统一了以下三项能力：
- **从少量观察中重建 3D 场景**；
- **在更多观察到来时持续更新与细化重建**；
- **推断未观测区域的 3D 结构**。

- 输入一段图像流后，递归模型会：
- 维护并不断更新一个内部的持久状态，用以编码场景内容
- 每当接收到一张新图像，它会更新状态，从状态中读取信息
- 最终预测出，当前视角的密集3D点图，当前图像的相机参数
- 通过对点图进行累计，可以实现在线的密集场景重建
- 此外，能够处理未观测视角，给定一个虚拟相机的射线图，模型可从状态中读取相应的结构与颜色，进而生成该虚拟视角的点图
![](img/Pasted%20image%2020251204005748.png)

## 相关工作

- 白纸式3D重建
- 每个新场景都从0开始建模，只依赖于可见的观测，没有跨场景记忆。
- 典型代表
- SfM
- SLAM
- NeRF
- 3DGS
- 在稀疏，退化，或有歧义的观测条件下容易失败，因为它们缺乏数据驱动的先验。

- 基于学习的3D重建
- 改进经典重建管线
	- 用学习特征取代SIFT/SURF特征
	- 在SfM中映入学习priors
	- 构建端到端可优化的SfM/MVS系统
	从单张图或图像对直接回归3D

- 连续式在线重建
- 相关并行工作 Spann3R
- 使用空间记忆进行连续重建
- 记忆主要是缓存已观测内容
- 无法像CUT3R的压缩状态那样推断未观测区域
- 且主要面向静态场景

- 动态场景的单目重建
- Robust-CVD：使用变形样条对深度进行时序对齐
- CasualSAM：针对单段视频微调深度模型
- MonST3R：将 DUSt3R 扩展到动态场景
- 这些方法通常依赖：
	- 视频级别的优化（耗时）
	- 额外的全局对齐 / 光流信息
	- 不具备完全在线能力

- 场景3D先验
- 从未观测视角推理3D内容
- 但多数方法：
	- 依赖输入相机参数
	- 限于物体级场景
	- 或需额外的 3D distillation 步骤
	- 多以新视角生成（novel view synthesis）作为间接目标
- CUT3R 的特性则是几何中心（geometry-centric）：
	- 直接生成虚拟相机视角的度量尺度点图
	- 不需要相机内参或外参作为输入
	- 场景来自任意数量的原始图像
	- 结构预测不是生成式，而是显式的 3D 点图推理

## 方法

- 3.1 状态与输入的交互机制

- 图像编码为视觉tokens
	- Ft = encoder(It)

- 状态标识为token集
	- 状态由一组可学习的tokens表示
	- 序列开始前，状态初始化为统一的，可训练的token
	- 随时间更新，状态逐步积累场景的3D信息

- 图像tokens与状态tokens的双向交互
	- 通过两个相互连接的transformer解码器同步交互

- 从交互结果中解码显式3D表示
	- 自身坐标系下的点图
	- 世界坐标系下的点图
	- 当前帧相机位姿

- self/world/pose
	- self可直接与单帧深度supervision对齐
	- world点图提供跨帧一致性
	- pose提供相机外参监督

![](img/Pasted%20image%2020251204163012.png)

- 3.2 用未观测视角查询状态

- 虚拟相机以Raymap作为输入
- Ray tokens与tokens的交互
- MAE的3D版本

- 3.3 训练目标

- 3D回归损失
![](img/Pasted%20image%2020251204163108.png)
- 相机位姿损失 
![](img/Pasted%20image%2020251204163134.png)
- Raymap的RGB监督损失
![](img/Pasted%20image%2020251204163201.png)

- 3.4 训练策略
- Encoder: ViT-L 来自DUSt3R
- Decoder: ViT-B
- Patch size: 16x16
- token数: 768
- Raymap encoder: 2-block Transformer
- 设备 8xA100 80GB

## 实验

![](img/Pasted%20image%2020251204163552.png)